{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# textgenrnn 1.0 Demo\n",
    "\n",
    "by [Max Woolf](http://minimaxir.com)\n",
    "\n",
    "*Max's open-source projects are supported by his [Patreon](https://www.patreon.com/minimaxir). If you found this project helpful, any monetary contributions to the Patreon are appreciated and will be put to good creative use.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "textgenrnn is a Python module on top of Keras/TensorFlow which can easily generate text using a pretrained recurrent neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from textgenrnn import textgenrnn\n",
    "\n",
    "textgen = textgenrnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Text\n",
    "\n",
    "The `generate` function generates `n` text documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Idea] The Bell Art Series Took New Performance\n",
      "\n",
      "[Humor] I want to see a friend that the main doesn't have to watch them in the season.\n",
      "\n",
      "What is the bad show and thinks he wants to stay me to do anything.\n",
      "\n",
      "What is the doom when people show me that they take a community of the problems?\n",
      "\n",
      "How to get still a boy and it's not supposed to stay to share the show of my characters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, you can set the `temperature` to modify the amount of creativity (default 0.5; I do not recommend setting to more than 1.0), set a `prefix` to force the document to start with certain characters and generate characters accordingly, and set a `return_as_list` flag (default False) to use the generated texts elsewhere in your application (e.g. as an API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Trump is a big decision of the state of the state of the story of the world...', 'Trump companies to the series of the start in the same story of the most poster in the most poster in the background and then see if you have a stranger and then the other party shows the end of the world in the same state with a community of the state of the shop when you have a good design to be', \"Trump is a programming back in a base to the first time and the first time that I don't know what to do it?\", 'Trump confirms a complete shot of the state of the state of the state of the state of the state of the state of the season to the state of the state of my parents for the state of the man who was a good day.', 'Trump is the best second of the state of the state of the state of the shape of the world.']\n"
     ]
    }
   ],
   "source": [
    "generated_texts = textgen.generate(n=5, prefix=\"Trump\", temperature=0.2, return_as_list=True)\n",
    "print(generated_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `generate_samples()` is a great way to test the model at different temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "I was an accident and I was a subreddit at the same person in the world is a lot of the most second of the state of the state of the state of the state of the state of the same card starting a community on the same state of the state of the state of the party in the state of the starter of the sta\n",
      "\n",
      "The Mario on Twitter: \"I just got my first time in the most poster and a bit of the party in the most book and have been released and want to see the strange to the state of the state of the state of the most and then going to make a program and I can be able to say they are a bot to make a strang\n",
      "\n",
      "I want to see the top of the same state of the same story of the state of the same time in the first time in the same time to the state of the startup of the computer is the only one to get the way to start started the state of the state of the background of the world is a post in the most and the\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "How do I have the best content to complain about someone and the team come back to a computer in the bottom to the controller that makes me the most upvoted president three parents on the world after the bad land is looking for a new big daughter\n",
      "\n",
      "The American Discussion is fully the other days to expect a wondering is too much of the news and go to fight in the Lichon is making her based on the development and don't know what I do?\n",
      "\n",
      "This is the little day and I have a staff in a weirdest and made you to proceed.\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "American Guitar guy's dream contest TOOUHIOS like Inlegit alarm in a great person to prevent users for anxiety\n",
      "\n",
      "Which common cheats in r/latest?\n",
      "\n",
      "[Urgiotism] events Alcohol Seruel Lands ( ͡°’s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may also `generate_to_file()` to make the generated texts easier to copy/paste to other sources (e.g. blog/social media):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgen.generate_to_file('textgenrnn_texts.txt', n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on New Text\n",
    "\n",
    "As shown above, the results on the pretrained model vary greatly, since it's a lot of data compressed in a small form. The `train_on_texts` function fine-tunes the model on a new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 1.4906\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "Never gonna gight you down\n",
      "\n",
      "Never gonna give a gay agair against aro=ggy\n",
      "\n",
      "Never gonna gigg gonna gir againt aroas\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Never gay agr art at gay\n",
      "\n",
      "Never gonna gigg aurount to you\n",
      "\n",
      "Never gonna give up\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Stirt agant as try add agf for great gonna game\n",
      "\n",
      "Never gongaa grome never never art 2 yea=?\n",
      "\n",
      "Never guy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = ['Never gonna give you up, never gonna let you down',\n",
    "            'Never gonna run around and desert you',\n",
    "            'Never gonna make you cry, never gonna say goodbye',\n",
    "            'Never gonna tell a lie and hurt you']\n",
    "\n",
    "textgen.train_on_texts(texts, num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the network was only trained on 4 texts, the original network still transfers the latent knowledge of all modern grammar and can incorporate that knowledge into generated texts, which becomes evident at higher temperatures or when using a prefix containign a character not present in the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can reset a trained model back to the original state by calling `reset()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgen.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Included in the repository is a `hacker-news-top-2000.txt` file containing a list of the Top 2000 [Hacker News](https://news.ycombinator.com/news) submissions by score. Let's retrain the model using that dataset.\n",
    "\n",
    "For this example, I only will use a single epoch to demonstrate how easily the model learns with just one pass of the data: I recommend leaving the default of 50 epochs, or set it even higher for complex datasets. On my 2016 15\" MacBook Pro (quad-core Skylake CPU), the dataset trains at about 1.5 minutes per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 texts collected.\n",
      "Epoch 1/1\n",
      "83491/83491 [==============================] - 106s 1ms/step - loss: 1.9068\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "Why I hade a service of my side in a server\n",
      "\n",
      "Why I hade a company in my side in its programmer\n",
      "\n",
      "Startup Startup Startup Introducing Software For Frame\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Who is haded a commerce completional software experiment for a learnarm\n",
      "\n",
      "The Support Use Introducing Book From Drugs\n",
      "\n",
      "I made me I founn the code in the US company is introducing in it\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Imple on Star UnSQL Dropbow\n",
      "\n",
      "Firefit for Ya comments down\n",
      "\n",
      "Encords the up tickeu deveromerities last services intervert\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.train_from_file('../datasets/hacker_news_2000.txt', num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create very distinctly-HN titles, even with the very little amount of training, thanks to the pre-trained nature of the textgenrnn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Startups in Global\n",
      "\n",
      "Apple HN: A Specifim to A Future of Facebook\n",
      "\n",
      "Apple Startups Are Murdered From Backship For Selling For Company\n",
      "\n",
      "Apple experience bank hacking the Housing Ask How I Found By Fast\n",
      "\n",
      "Apple Completion Structures Chart\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(5, prefix=\"Apple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other runtime parameters for `train_on_text` and `train_from_file` are:\n",
    "\n",
    "* `num_epochs`: Number of epochs to train for (default: 50)\n",
    "* `gen_epochs`: Number of epochs to run between generating sample outputs; good for measuring model progress (default: 1)\n",
    "* `batch_size`: Batch size for training; may want to increase if running on a GPU for faster training (default: 128)\n",
    "* `prop_keep`: Random proportion of sequence samples to keep: good for controlling overfitting and reducing memory required to process the data. (default: 1.0/all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load the Model\n",
    "\n",
    "The model saves the weights automatically after each epoch, or you can call `save()` and give a HDF5 filename. Those weights can then be loaded into a new textgenrnn model by specifying a path to the weights on construction. (Or use `load()` for an existing textgenrnn object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "Why I hade my side programmers\n",
      "\n",
      "Why I founn the Found Startup\n",
      "\n",
      "Why I am helped me and I can't be software the service of my programmers\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "A day of More India\n",
      "\n",
      "Braund Programmers in Facebook\n",
      "\n",
      "Amazing Source Brand Employees\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "I hade etclytelin Gamebraby streamer\n",
      "\n",
      "Servicer Cosment is cull AI\n",
      "\n",
      "App Iska by I thought\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen_2 = textgenrnn('textgenrnn_weights.hdf5')\n",
    "textgen_2.generate_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textgen.model.get_layer('rnn_1').get_weights()[0] == textgen_2.model.get_layer('rnn_1').get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the weights between the original model and the new model are equivalent.\n",
    "\n",
    "You can use this functionality to load models from others which have been trained on larger datasets with many more epochs (and the model weights are small enough to fit in an email!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "A lesson on the importance of encouraging your children with their projects\n",
      "\n",
      "A letter to our daughter\n",
      "\n",
      "Show HN: Make a programmable mirror\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Ask HN: What was your “why didn't I start doing this sooner” moment?\n",
      "\n",
      "Show HN: This up votes itself\n",
      "\n",
      "The Star Wars Route: Do a traceroute to 216.81.59.173\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Encryption, Practice Roman, acquired Server\n",
      "\n",
      "An off-grid social network\n",
      "\n",
      "Farm Has Me Maybeat Armoill\n",
      "\n",
      "####################\n",
      "Temperature: 1.2\n",
      "####################\n",
      "A Gmai Now Think It Costs Got Upbot\n",
      "\n",
      "Amit Gupta has passwording aliswry that  tool to take\n",
      "\n",
      "Linus Torvalds: Successful projects are 99% perspiration and 1% innovation\n",
      "\n",
      "####################\n",
      "Temperature: 1.5\n",
      "####################\n",
      "Panamapov Airplisswackｐa, MK, and More Free?\n",
      "\n",
      "Oracle v. Google - Diviscons The Guy used a Kaby Developer in the Armuloz\n",
      "\n",
      "Ask HN: How to be entitumal tolve out one persona\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen = textgenrnn('../weights/hacker_news.hdf5')\n",
    "textgen.generate_samples(temperatures=[0.2, 0.5, 1.0, 1.2, 1.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a New Model\n",
    "\n",
    "You can train a new model using any modern RNN architecture you want by calling `train_new_model` if supplying texts, or adding a `new_model=True` parameter if training from a file. If you do, the model will save a `config` file and a `vocab` file in addition to the weights, and those must be also loaded into a `textgenrnn` instances.\n",
    "\n",
    "The config parameters available are:\n",
    "\n",
    "* `word_level`: Whether to train the model at the word level (default: False)\n",
    "* `rnn_layers`: Number of recurrent LSTM layers in the model (default: 2)\n",
    "* `rnn_size`: Number of cells in each LSTM layer (default: 128)\n",
    "* `rnn_bidirectional`: Whether to use Bidirectional LSTMs, which account for sequences both forwards and backwards, and perform especially well with the Attention layer (default: False)\n",
    "* `max_length`: Maximum number of previous characters/words to use before predicting the next token. This value should be reduced for word-level models (default: 40)\n",
    "* `max_words`: Maximum number of words (by frequency) to consider for training (default: 10000)\n",
    "* `dim_embeddings`: Dimensionality of the character/word embeddings (default: 100)\n",
    "\n",
    "You can also specify a `name` when creating a textgenrnn instance which will help name the output weights/config/vocab appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgen = textgenrnn(name=\"new_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training new model w/ 1-layer, 128-cell LSTMs\n",
      "Epoch 1/10\n",
      "40/40 [==============================] - 1s 15ms/step - loss: 3.0977\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 0s 125us/step - loss: 2.7638\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 0s 135us/step - loss: 2.0045\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 0s 134us/step - loss: 1.3166\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 0s 134us/step - loss: 1.0642\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "never gonna tell you lie , never gonna tell you lie , and gonna you you , , gonna gonna you you , , gonna gonna you you , , gonna gonna you you , , gonna gonna you you\n",
      "\n",
      "never gonna let you down\n",
      "\n",
      "never gonna run you and\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "never gonna give you cry , never gonna make you cry , never gonna tell a lie and hurt you\n",
      "\n",
      "never gonna give you up , never gonna tell a lie and hurt you , , gonna make you cry , never gonna say goodbye\n",
      "\n",
      "never gonna say you\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "never gonna lie around and and you you\n",
      "\n",
      "never gonna make let you let , around gonna gonna you you down , , gonna tell lie hurt hurt you\n",
      "\n",
      "never gonna run around desert never\n",
      "\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 0s 131us/step - loss: 0.7635\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 0s 149us/step - loss: 0.6223\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 0s 129us/step - loss: 0.5462\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 0s 125us/step - loss: 0.5026\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 0s 128us/step - loss: 0.4793\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "never gonna let you down\n",
      "\n",
      "never gonna make you cry , never gonna make you cry , never gonna let you down\n",
      "\n",
      "never gonna tell a lie and hurt you\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "never gonna tell a lie and hurt you\n",
      "\n",
      "never gonna give you up , never gonna make you you\n",
      "\n",
      "never gonna say goodbye\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "never gonna you\n",
      "\n",
      "never gonna give you up , never gonna tell a you and\n",
      "\n",
      "never gonna run around and hurt you\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 2, 100)       2200        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (LSTM)                    (None, 2, 128)       117248      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_concat (Concatenate)        (None, 2, 228)       0           embedding[0][0]                  \n",
      "                                                                 rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attention (AttentionWeightedAve (None, 228)          228         rnn_concat[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 22)           5038        attention[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 124,714\n",
      "Trainable params: 124,714\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "texts = ['Never gonna give you up, never gonna let you down',\n",
    "            'Never gonna run around and desert you',\n",
    "            'Never gonna make you cry, never gonna say goodbye',\n",
    "            'Never gonna tell a lie and hurt you']\n",
    "\n",
    "textgen.train_new_model(texts,\n",
    "                        word_level=True,\n",
    "                        rnn_layers=1,\n",
    "                        max_length=2,\n",
    "                        num_epochs=10,\n",
    "                        gen_epochs=5)\n",
    "\n",
    "print(textgen.model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 texts collected.\n",
      "Training new model w/ 2-layer, 64-cell Bidirectional LSTMs\n",
      "Epoch 1/1\n",
      "83491/83491 [==============================] - 152s 2ms/step - loss: 2.5867\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "A stere to searne stere with with witte with with wat low to ling source with with source lowser of how with the mane and the sears dears in the stere to with with with with with will and in with with the stere stere pase lowne lowser with with wayte with with with with worke to in indine to lis w\n",
      "\n",
      "The Inter Google Internete Internete Inter Inter Interneters\n",
      "\n",
      "A now with with ster of with with in the ster the with we dith with watter with with weble dite lister and source with the webs stere with sources and with with weble downer with dith with with we the dinters with we with watter and with work source of with lowse of the will sears of dow the dith \n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "The Linter and the some and compers downite lome think geans\n",
      "\n",
      "Intenver Storte Inster Interrester Interseres\n",
      "\n",
      "Ande Hantres in Anternete for pare and and the book lore fill inter ande dive wistuble fite stese seam inse fire wean the sourced webser pementing dors\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Gintod Chrvains Inecmons of hditt shass Sp\n",
      "\n",
      "CSROcle sommed of maw rofile mewal Atte-denul Siglerions one initidine hearned?\n",
      "\n",
      "+€Watis Wistemon, wind? Deea nreal” leace wam your lere? azess\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 40, 300)      31500       input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_1 (Bidirectional)           (None, 40, 128)      186880      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "rnn_2 (Bidirectional)           (None, 40, 128)      98816       rnn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "rnn_concat (Concatenate)        (None, 40, 556)      0           embedding[0][0]                  \n",
      "                                                                 rnn_1[0][0]                      \n",
      "                                                                 rnn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "attention (AttentionWeightedAve (None, 556)          556         rnn_concat[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 105)          58485       attention[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 376,237\n",
      "Trainable params: 376,237\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "textgen.reset()\n",
    "textgen.train_from_file('../datasets/hacker_news_2000.txt',\n",
    "                        new_model=True,\n",
    "                        rnn_bidirectional=True,\n",
    "                        rnn_size=64,\n",
    "                        dim_embeddings=300,\n",
    "                        num_epochs=1)\n",
    "\n",
    "print(textgen.model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "A searce searn searnte source with wind worke source lose source with with with inter watter and with watter and the ster and will downer with the we watter and with source sill and with dith with watte to dite and with and with we dind will source with with with searce source with sources warking\n",
      "\n",
      "A and and with wat and source and with and dite of the and chese searn with watte lowne source to lessers\n",
      "\n",
      "A now the ster source pase to low with with with with with the web and to dite with make lowner searce worker with with with with stare and ditters with with with with with with with with with with with with pace lowne to ster and dite lose side of steral dith fill lide the dite to line dinters\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Firs Humis A cesessers\n",
      "\n",
      "Shew Inter List Learte Firte At Bowar Interrete Inter Show HN: Intromer Inter seve wister worke bary dite of source the your we source of mystter Inter source with in sild inte and to seres in an now dill make my sercesser and Google loster the tens fore low starce to stuted boil\n",
      "\n",
      "The Instenter Inter Anle Wacked Indicter and Comparnteste Janter Google for Fillen Show Intictersing to the walls\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "A not and Ips to sedys\n",
      "\n",
      " hhankenker suaned ssomenys\n",
      "\n",
      "SelaS: Forusfing Combude Exesle\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen_2 = textgenrnn(weights_path='new_model_weights.hdf5',\n",
    "                       vocab_path='new_model_vocab.json',\n",
    "                       config_path='new_model_config.json')\n",
    "\n",
    "textgen_2.generate_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Single Large Text\n",
    "\n",
    "Although textgenrnn is intended to be trained on text documents, you can train it on a large text block using `train_from_largetext_file` (which loads the entire file and processes it as if it were a single document) and it should work fine. This is akin to more traditional char-rnn tutorials.\n",
    "\n",
    "Training a new model is recommended (and is the default). When calling `generate`, you may want to increase the value of `max_gen_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training new model w/ 2-layer, 128-cell LSTMs\n",
      "Epoch 1/1\n",
      "600894/600894 [==============================] - 669s 1ms/step - loss: 2.0981\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "or in the same self-perhaps the relative the morality the sense of the relative the since of the same relative the morality the seems of the seems of the relatification of the sense of the relatification of the seems the destint the relative the sense of the sentiment of the seems the relatificati\n",
      "\n",
      "or the sense of the sense of the sentiment of the perhaps a morality the relative the seems of the sense of the seems the relative the sense of the relative the sense of the sense of the sense of the sense of the sense of the relatified the present the contempt of the same self-desting the moralit\n",
      "\n",
      "or and the same so the relatified the person and the perhaps in the same and desting the sentiment of the relation of a desting the relative the relative the man in the sense of interto the relative the relative the sense of the relative the seems the sense of seems of the seems of the same of the\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "or in the same and means of the INCE in the incluently point of the might the seems to the rependinated will even to a morto the continuous intepticely of the perhaps destingly he deception of a morality is so book only repending to the since and until the relatified in the repurt destriction of t\n",
      "\n",
      "to\n",
      "power, the time of the nours and morality as a langer the porther contempt in the refunting that the sense of to the not perception of even the same desting to the sees at the regardly so nouthing perhaps even the since definds to the relatified destrictions and reconting the somes of a delight\n",
      "\n",
      "press\n",
      "of the seems of the stright of a dew dare of self-refince of the rest so the relatified not to the world sees he same false of the religion of the entire the subtle of a contement of his word of the traster and the seems of the still the perhaps to the deself--and person the still of mention\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "NET So-tin,\"\n",
      "souls, neces, to his world?\n",
      "\n",
      "           Dath out of denement\n",
      "in factionds, pawers\n",
      "to a\n",
      "cate it would not has subome in bain\n",
      "own naties for a can but the facisont,\n",
      "\"every her It only wrrck a cortual, good statedly blass!\n",
      "it I\n",
      "the clanement\n",
      "thesia as the remost they. Nature relutise out\n",
      "\n",
      "therself, is posting unto evan of has despocious, them. There thy occased. Along or espimate\n",
      "dissut in Intellectual's newh, it of would narbors can of evil; to the new last,\n",
      "as an wongerient a mile resuls hove trans as \"terled pacrequenteMIty and to sicustic, also subt then his tep a most\n",
      "seemed o\n",
      "\n",
      "ee, forth'old, the\n",
      "continct!\" they fact eymy spealposely and rume, xinds of\n",
      "the systooms of humanity really \"ineponting in dissfores in the into he something re's a nack\n",
      "would nobb Fooch CANCE: Is ENTESERLATINGESING\n",
      "kinds had TE!\n",
      "\n",
      "\n",
      "                                          Bys\n",
      "i man and here wrile\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "fulltext_path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "\n",
    "textgen.reset()\n",
    "textgen.train_from_largetext_file(fulltext_path, new_model=True, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I the sense of the morality for which disconders of the relation to the morals\n",
      "its ourselves of the sense of the sill of the whole as the subter of the into short the view to delution of the unterportant; and not who is not dealthy who seems the decidest of the worsting in the former at the seemed the meant of rangerous partunation of the relative and not only the man of the sined\n",
      "and a not one of a mind of a greation of value saint of the substicate in the recommens as the relatification of the seems of morality in the same relative the mort a stronger former of evil will one sense of men the others who, the decided for the the man not the sentiment of like as the redution of the perhaps it of the more of the relative to which has not to greated regard of the same believe therefore will for the regarded of the into the same mut to the same in the might in the man of the matter free dance to not himself, one hertically so the truth and pertain and allow of moral, of the world of a lo\n",
      "\n",
      "gre to nes the contrase by it is in the continction of the sense the expention, world the still has distrosons of substicately the relative the person the time the person the relatification of the morality in the rignt to really the seems of the relatifice of a dissition the relative the each of the self-present like of it has attempt the rest the sympors and in the sense very possible of a morality the man of who has beens of the power enough the perfulness of a long can to the perhaps for a called the perhaps for the\n",
      "soul, it is it is of the lastle my a satiself endure the relative a contert and the very\n",
      "decosted in the same suffines the fastion of which eys and the subtle of the may espection of with which religion of the seems the sentiment of the conduction of the man and end mere and and means in the strong disconsine the relative the Christianity of formers of the relation it always\n",
      "the perhaps\n",
      "delight the relative that the necessary the intulled in the have forthing never a v\n",
      "\n",
      "constriction of the most relatification to the propertative free dablithing of the\n",
      "self-devents of the desticate here profound and the man and were that it is own emotion of detically man of the mystitrant to the man presertant and self-subtulness, of the erpother to relative\n",
      "the revelopment of his expenting every delatified and precisely the refonstice of the sense of life in himself, they has been therefore the same last easted who subtle the special dost every seces the every the remanting in the mest to will nature the seemines of the proses, the relations of the religion to the syster of the person the man words to perhaps\n",
      "distors of its relution of not ruch as the religion of the morality of the same proals of a sentiment of the solest has not it is a sense of a morals with the there is a ratho, of the his not proted a means of a bras in its relatifice, the contidertation of which is to the subter at into and the perception in the relatific and in the person the will it it is n\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textgen.generate(3, max_gen_length=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LICENSE\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2018 Max Woolf\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
