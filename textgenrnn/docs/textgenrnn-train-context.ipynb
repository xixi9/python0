{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# textgenrnn Training with Context\n",
    "\n",
    "by [Max Woolf](http://minimaxir.com)\n",
    "\n",
    "*Max's open-source projects are supported by his [Patreon](https://www.patreon.com/minimaxir). If you found this project helpful, any monetary contributions to the Patreon are appreciated and will be put to good creative use.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "textgenrnn is a Python module on top of Keras/TensorFlow which can easily generate text using a pretrained recurrent neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from textgenrnn import textgenrnn\n",
    "\n",
    "textgen = textgenrnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on New Text\n",
    "\n",
    "Here's textgenrnn trained on a dataset of the Top 1000 submissions to /r/politics and /r/rarepuppers during 2017: two subreddits with drastically different styles! How well can a new model learn these styles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 texts collected.\n",
      "Training new model w/ 2-layer, 128-cell LSTMs\n",
      "Epoch 1/20\n",
      "114560/114560 [==============================] - 124s 1ms/step - loss: 3.1710\n",
      "Epoch 2/20\n",
      "114560/114560 [==============================] - 122s 1ms/step - loss: 2.2441\n",
      "Epoch 3/20\n",
      "114560/114560 [==============================] - 122s 1ms/step - loss: 1.9310\n",
      "Epoch 4/20\n",
      "114560/114560 [==============================] - 122s 1ms/step - loss: 1.7572\n",
      "Epoch 5/20\n",
      "114560/114560 [==============================] - 121s 1ms/step - loss: 1.6368\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "Trump administration of Trump interfered and president in the warned to the says\n",
      "\n",
      "President Trump Impeachment Is Mary Promise Comey to Russia investigation\n",
      "\n",
      "Trump to the Republicans to company to company to repeal internet intervery to the show the sheated in the mare than he was a heckin good boye\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "The Haraboore Council Malana a Than States\n",
      "\n",
      "Trump with says now state he day bet he administration for the Russia\n",
      "\n",
      "The GOP attended healthcare adminish Trump wart can and healthcare bill birth mode\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Trump-Twater tartly for come Democh of CNP was haltion\n",
      "\n",
      ". B I L G O D B O Y E\n",
      "\n",
      "President Trump's adore says on RYC GONâ€™s investigation\n",
      "\n",
      "Epoch 6/20\n",
      "114560/114560 [==============================] - 122s 1ms/step - loss: 1.5419\n",
      "Epoch 7/20\n",
      "114560/114560 [==============================] - 122s 1ms/step - loss: 1.4610\n",
      "Epoch 8/20\n",
      "114560/114560 [==============================] - 122s 1ms/step - loss: 1.3863\n",
      "Epoch 9/20\n",
      "114560/114560 [==============================] - 122s 1ms/step - loss: 1.3198\n",
      "Epoch 10/20\n",
      "114560/114560 [==============================] - 122s 1ms/step - loss: 1.2554\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "Trump to enjong to the difference\n",
      "\n",
      "Trump to seek Trump is and contacts and statement in the U.S. press be a big to the starts\n",
      "\n",
      "Trump to see a borker bamboozled and stoppers so the difference between bill in statement\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Donald Trump says he 'see from US Senate and the Republican Personal Resign\n",
      "\n",
      "Senate officials seek sending him on hell he sent the doggo\n",
      "\n",
      "Trump Senior Senate Republicans says Senate heard of the bear benathan called for President Trump\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Kush boye son, getting nive a post recovery\n",
      "\n",
      "Mueller officials: The Hemocrace Republican Posuters\n",
      "\n",
      "goodboye pupper does a big on heckin good BOOOK\n",
      "\n",
      "Epoch 11/20\n",
      "114560/114560 [==============================] - 121s 1ms/step - loss: 1.1907\n",
      "Epoch 12/20\n",
      "114560/114560 [==============================] - 122s 1ms/step - loss: 1.1309\n",
      "Epoch 13/20\n",
      "114560/114560 [==============================] - 122s 1ms/step - loss: 1.0710\n",
      "Epoch 14/20\n",
      "114560/114560 [==============================] - 122s 1ms/step - loss: 1.0144\n",
      "Epoch 15/20\n",
      "114560/114560 [==============================] - 122s 1ms/step - loss: 0.9574\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "Megathread: Manafort has been took of $2009 Bethed White House Was Approval Rally\n",
      "\n",
      "Trump administration is state despite 'contact with Russian ambassador the Republican Please Halfing to Democrats, Trump Tower in An Air Force\n",
      "\n",
      "Trump to delay to stop the U.S. senators should be a been with the majority of Trump\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Trump Water funned McConnell over to Russian ambassador day attacked for a president in the U.S. protesteduring me as water on least poopand to go a heckin big soncel\n",
      "\n",
      "Trump administration shows to be vice in election in 2016: '\n",
      "\n",
      "Donald Trump says 'consider the brought the White House comments\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Heckin proup big pupper in hocking rboosing\n",
      "\n",
      "I' skip, has to net Nevvo golf\n",
      "\n",
      "J I N P P E R S A N T\n",
      "\n",
      "Epoch 16/20\n",
      "114560/114560 [==============================] - 121s 1ms/step - loss: 0.9038\n",
      "Epoch 17/20\n",
      "114560/114560 [==============================] - 118s 1ms/step - loss: 0.8524\n",
      "Epoch 18/20\n",
      "114560/114560 [==============================] - 122s 1ms/step - loss: 0.8050\n",
      "Epoch 19/20\n",
      "114560/114560 [==============================] - 122s 1ms/step - loss: 0.7624\n",
      "Epoch 20/20\n",
      "114560/114560 [==============================] - 122s 1ms/step - loss: 0.7246\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "Megathread: Face the Carectual Kay Record\n",
      "\n",
      "Trump threatens to leave Trump in constitution of the president in has sent this is a real have not town frens\n",
      "\n",
      "Trump administration is state visit to Trump-Russia investigation\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Pupper does a heckin good doggo\n",
      "\n",
      "The White House Warns CNN Tessanders And Flynn Investigation Into Sush Mass Has Have tee\n",
      "\n",
      "Heckin big boye does a since corgo\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Trump back but over seements to email souct show\n",
      "\n",
      "Megathread: Fake pill confurs probe will in eardiscaus\n",
      "\n",
      "G E R E B O Y E sneam frens ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../datasets/reddit_rarepuppers_politics_2000.txt\"\n",
    "\n",
    "textgen.reset()\n",
    "textgen.train_from_file(file_path, new_model=True, num_epochs=20, gen_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the same dataset, trained with the context labels indicating the source subreddit. If using `train_from_file`, the input file must be a 2-column CSV, with the first column containing the texts and the second containing the labels.\n",
    "\n",
    "The `output_loss` is the loss along the text-only path. In this example, the context-label model has a slightly lower loss than the text-only training. (the more disparate the texts, the more helpful providing context will help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 texts collected.\n",
      "Training new model w/ 2-layer, 128-cell LSTMs\n",
      "Epoch 1/20\n",
      "114564/114564 [==============================] - 124s 1ms/step - loss: 3.0469 - context_output_loss: 3.0440 - output_loss: 3.0585\n",
      "Epoch 2/20\n",
      "114564/114564 [==============================] - 123s 1ms/step - loss: 2.2249 - context_output_loss: 2.2222 - output_loss: 2.2359\n",
      "Epoch 3/20\n",
      "114564/114564 [==============================] - 123s 1ms/step - loss: 1.9357 - context_output_loss: 1.9334 - output_loss: 1.9450\n",
      "Epoch 4/20\n",
      "114564/114564 [==============================] - 123s 1ms/step - loss: 1.7607 - context_output_loss: 1.7587 - output_loss: 1.7688\n",
      "Epoch 5/20\n",
      "114564/114564 [==============================] - 123s 1ms/step - loss: 1.6394 - context_output_loss: 1.6375 - output_loss: 1.6469\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "Trump to an Allegation Proude Bunder Him Sent to Revealed From Send Trump Addinate Defure Interlied and Trump Russian Mating Adainst Than He Was He Was Russian Court In Americans, â€˜Itâ€™s Americans, Interlied and Americans, It Was Wates, Its Americans, It Americans, It White House Was Wants, He Was \n",
      "\n",
      "More and the does a heckin bood boye\n",
      "\n",
      "The decaully the doggo does a h*ckin good boye a h*ckin good boye\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Trump to recuse But Bannon for Russia an Allagation House Final Donald Trump and Are Sent Russia Investigation of Defuse Reportment\n",
      "\n",
      "Trump been in anti-Trump to has a back after three a vs wanting\n",
      "\n",
      "Founder, the says should Trump to veter after furion for the matted for the Creard the bearers, the puppers,\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "A B O Y E H B O Y E\n",
      "\n",
      "The doffend.\n",
      "\n",
      "for-I apare theric\n",
      "\n",
      "Epoch 6/20\n",
      "114564/114564 [==============================] - 122s 1ms/step - loss: 1.5490 - context_output_loss: 1.5473 - output_loss: 1.5561\n",
      "Epoch 7/20\n",
      "114564/114564 [==============================] - 123s 1ms/step - loss: 1.4747 - context_output_loss: 1.4729 - output_loss: 1.4817\n",
      "Epoch 8/20\n",
      "114564/114564 [==============================] - 122s 1ms/step - loss: 1.3952 - context_output_loss: 1.3936 - output_loss: 1.4019\n",
      "Epoch 9/20\n",
      "114564/114564 [==============================] - 122s 1ms/step - loss: 1.3298 - context_output_loss: 1.3281 - output_loss: 1.3365\n",
      "Epoch 10/20\n",
      "114564/114564 [==============================] - 122s 1ms/step - loss: 1.2626 - context_output_loss: 1.2610 - output_loss: 1.2692\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "S M I L E Y G I R L E does a sancy a heckin good boye a heckin good boye and the mirrio\n",
      "\n",
      "Trump calls for chief the president in the secret with the president\n",
      "\n",
      "The beach of a brought a heckin heckin happy boye still in the stick\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Good boy to tell fren, cour stick on his to get the the pert in health care complice\n",
      "\n",
      "Heck the defed the cearing to send with souches court\n",
      "\n",
      "This pupper does a heckin sneezity in the has been in court and the new people\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "US vewen denept greak Trump's cated at Alabama' enghe' $13Miniling sacia susser executtioned divil us investigatorl sancer\n",
      "\n",
      "S M E R B O Y E doin a heckin bet a brimi rissition on the scoor tax tire colled to lut FBI impeach and cortal before â€” years: We ohe thingsâ€™ in NYC\n",
      "\n",
      "Petity counses matter calling ot they cut sanced to shave all him signed you howe :)\n",
      "\n",
      "Epoch 11/20\n",
      "114564/114564 [==============================] - 122s 1ms/step - loss: 1.1957 - context_output_loss: 1.1940 - output_loss: 1.2023\n",
      "Epoch 12/20\n",
      "114564/114564 [==============================] - 123s 1ms/step - loss: 1.1331 - context_output_loss: 1.1314 - output_loss: 1.1398\n",
      "Epoch 13/20\n",
      "114564/114564 [==============================] - 118s 1ms/step - loss: 1.0702 - context_output_loss: 1.0686 - output_loss: 1.0768\n",
      "Epoch 14/20\n",
      "114564/114564 [==============================] - 123s 1ms/step - loss: 1.0095 - context_output_loss: 1.0078 - output_loss: 1.0161\n",
      "Epoch 15/20\n",
      "114564/114564 [==============================] - 122s 1ms/step - loss: 0.9511 - context_output_loss: 0.9495 - output_loss: 0.9577\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "Trump campaign had discuss for pobital after begelf committed a good bork the laws he laws a snuggle!\n",
      "\n",
      "Trump Says He Can Have a National Security Council\n",
      "\n",
      "Trump claims the man halkous from bowe doesn't time in 10 weeks and the speech of he can for schmackos!\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "Pupper donations discrimination class\n",
      "\n",
      "Donald Trump cancels plan to longer Memo dessial correct\n",
      "\n",
      "White House first two make than my collup in scandal\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Roy Moore Wasn Must Siglence ;mail Didn\n",
      "\n",
      "I do litest rembunds fac\n",
      "\n",
      "Promined Dom thats his damplother\n",
      "\n",
      "Epoch 16/20\n",
      "114564/114564 [==============================] - 122s 1ms/step - loss: 0.8942 - context_output_loss: 0.8926 - output_loss: 0.9008\n",
      "Epoch 17/20\n",
      "114564/114564 [==============================] - 122s 1ms/step - loss: 0.8428 - context_output_loss: 0.8411 - output_loss: 0.8494\n",
      "Epoch 18/20\n",
      "114564/114564 [==============================] - 122s 1ms/step - loss: 0.7932 - context_output_loss: 0.7916 - output_loss: 0.7998\n",
      "Epoch 19/20\n",
      "114564/114564 [==============================] - 122s 1ms/step - loss: 0.7491 - context_output_loss: 0.7475 - output_loss: 0.7557\n",
      "Epoch 20/20\n",
      "114564/114564 [==============================] - 122s 1ms/step - loss: 0.7107 - context_output_loss: 0.7091 - output_loss: 0.7172\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "Trump takes to beep oll big was a lamboozle instead. ... or the need white man who sold shows first president in the president\n",
      "\n",
      "Trump takes agrees Alleged bork this president in stracked by GOP\n",
      "\n",
      "S M I L E Y B O Y E\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "The beaches grow the doggo doesn't snow the demarted Debated\n",
      "\n",
      "P O M F Y B O Y E doin a heckin good scriet\n",
      "\n",
      "Trump administration is day in a good boye stal protestors\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "Here's a heckin mat you splooves, sign, it.â€™ (WWhen is maning to make he letwered back : ind transcis\n",
      "\n",
      "My Getfirning the GOP to More Amendment, takes just talket people to trilk about my doesn't know as J L A T O T H Y doggo!! Iâ€™m a heckin good boye\n",
      "\n",
      "Donald Trump to get a Sanctions while Obama\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../datasets/reddit_rarepuppers_politics_2000_context.csv\"\n",
    "\n",
    "textgen.reset()\n",
    "textgen.train_from_file(file_path, new_model=True, num_epochs=20, gen_epochs=5, context=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use `train_on_texts` with context labels as well by providing a list of context labels of the same size as the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training new model w/ 2-layer, 128-cell LSTMs\n",
      "Epoch 1/10\n",
      "174/174 [==============================] - 1s 6ms/step - loss: 3.1777 - context_output_loss: 3.1681 - output_loss: 3.2160\n",
      "Epoch 2/10\n",
      "174/174 [==============================] - 0s 251us/step - loss: 6.5595 - context_output_loss: 6.7623 - output_loss: 5.7484\n",
      "Epoch 3/10\n",
      "174/174 [==============================] - 0s 240us/step - loss: 2.9979 - context_output_loss: 3.0082 - output_loss: 2.9566\n",
      "Epoch 4/10\n",
      "174/174 [==============================] - 0s 252us/step - loss: 2.4471 - context_output_loss: 2.4238 - output_loss: 2.5401\n",
      "Epoch 5/10\n",
      "174/174 [==============================] - 0s 253us/step - loss: 2.3551 - context_output_loss: 2.3393 - output_loss: 2.4183\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "eeee ooonaaeee ooooa aa ere ononare  oon aeee  oonnar eoonnnaaere oononara e oaounea  eo nanaeeerooonnaaaee eoon naaaeeeeooooneaeaeo o ner  onn aaeer oonnr ae no n e   noaanaereroononeae  o oaaueee ooonaaaeeeroooonaaeeee oooneare oonnaaaeereooonnaeata oeaen o nae a eo eooo naee  oooaa  eeo nonaaaa\n",
      "\n",
      "eeee oonna eaeeoo onneeae oonneraoooneae  oonaaayreeonoone ea o ne n eo aonaeeae on neare onnneaer ooonanaeer oonneaee ooooa ee  oooanaeee oonnaeaeeonooneaeeuoonna eeeoonnneae  oaneeeroononeaae o nneaee ooonaaraea n aeae  o na rv onnuaereooonnea eooeou onanaeeea ooneaa e e onnneree noooeeaa on eae\n",
      "\n",
      "eeee oonna aeeeoooonn   aer ooon eaeao  nea erooonnaaaeeeeooonoaaeeeeoooonae  a   aee noooaaaae r oonneaer ononaaaree onnoaaeaae   ooaaaer  oonnaaeeee ononaaeaaero nonaere oonn rateon unea n oeee ooonaaeaer ooonea ern nonaeee ooon eaeeoooonaaaeee oonnraer nooneeo  nnee e ooona eee oonnaaeeaeuoo na\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "eeee ooooule oauga eoueonnona raeononneuaeen eooenoaaaeego nueaeeuneoounyge oony eueooaune e en oaav aeno err  noa aN rve nuoan e  eouoedea eenegnoe  roovoarrununoaeyevnonoaarrueonun   nyaaeeuuoonavu vooanuk r oounue gaoneurooonnvaaeeo oo u euon ooteeaunooeeaooootnre oeonavueerononaveuu noavee eno\n",
      "\n",
      "eeeeeouooonrdaee e onnaen rdoa  ea oonvneoenaoanenaeaga o eennno eee nnnna  e eononooeraann eee non u rrnnonoraaegoeao  ueyrooonnaad eyeeonon vre ononaeraeuonu es oeounuoa adeeeeyooogen   neorn yroanournenano eiv  ononeaea\n",
      "\n",
      "evNerooonn\n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "eee eoonondeaavvovng nergo nrnaoeanero ng,tla takri nonesanonerr\n",
      "\n",
      "aeeeNl on yetr ,oc eeuoonodatltvuynuuavrknrnaagaviaoa  uaateerodoonnamavgeu uau rgdoonddyserc\n",
      "\n",
      "veve ugoncne,orreengnortahuoaovrrnguuoe eyng nn ensig ennaat nrcdr aavgauoonoe,owtderklgounmavarNanvderdnt nshuvedunoeioa  e  diuenmtu derobunoaeenrlo ogn,werNto gealnl roauoe,rovoe uoaaeayoseenannartoo adt u taeon eyualuda alryrannvov\n",
      "\n",
      "Epoch 6/10\n",
      "174/174 [==============================] - 0s 268us/step - loss: 2.1778 - context_output_loss: 2.1575 - output_loss: 2.2587\n",
      "Epoch 7/10\n",
      "174/174 [==============================] - 0s 258us/step - loss: 2.0475 - context_output_loss: 2.0260 - output_loss: 2.1334\n",
      "Epoch 8/10\n",
      "174/174 [==============================] - 0s 272us/step - loss: 1.9805 - context_output_loss: 1.9621 - output_loss: 2.0540\n",
      "Epoch 9/10\n",
      "174/174 [==============================] - 0s 277us/step - loss: 1.9065 - context_output_loss: 1.8857 - output_loss: 1.9897\n",
      "Epoch 10/10\n",
      "174/174 [==============================] - 0s 297us/step - loss: 1.8368 - context_output_loss: 1.8127 - output_loss: 1.9330\n",
      "####################\n",
      "Temperature: 0.2\n",
      "####################\n",
      "eeee goon a\n",
      "\n",
      "eeee goona aae    o   da aeer  gnn  aae     a            a    y   nd aaee   oo dn\n",
      "\n",
      "eeee  oon y\n",
      "\n",
      "####################\n",
      "Temperature: 0.5\n",
      "####################\n",
      "eeee ggna  vy aooye w un u re onna ea   u    a  e y  on\n",
      "\n",
      "NveNr gonna eara ugn  a lt   byud\n",
      "\n",
      "eeee oogganaader \n",
      "\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      "vveaeoon rmn ngym er rgondwntNlrdyaunvu  go ondna\n",
      "\n",
      "eeaaro \n",
      "\n",
      "NNeer goonllgad  gkvdeoonned\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = ['Never gonna give you up, never gonna let you down',\n",
    "            'Never gonna run around and desert you',\n",
    "            'Never gonna make you cry, never gonna say goodbye',\n",
    "            'Never gonna tell a lie and hurt you']\n",
    "\n",
    "context_labels = ['Verse 1', 'Verse 1', 'Verse 2', 'Verse 2']\n",
    "\n",
    "textgen.reset()\n",
    "textgen.train_new_model(texts, context_labels=context_labels, max_length=5, gen_epochs=5, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LICENSE\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2018 Max Woolf\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
